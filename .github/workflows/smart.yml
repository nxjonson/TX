name: smart

on:
  schedule:
    - cron: '45 21 */2 * *'
  workflow_dispatch:
    inputs:
      logLevel:
        description: 'Log level'
        required: true
        default: 'warning'
        type: choice
        options:
          - info
          - warning
          - debug

jobs:
  filter:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # 使用一个稳定的 Python 版本

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests # 安装 requests 库

      - name: Download and process playlists
        run: |
          python3 <<'PY'
import re
import requests
from pathlib import Path

# --- 配置 ---
# 源1配置
source1_url = "https://raw.githubusercontent.com/judy-gotv/iptv/refs/heads/main/smart.m3u"
source1_file = "/tmp/smart.m3u"
allowed_group1 = "GPT-台湾"

# 源2配置
source2_url = "http://2099.tv12.xyz/list.txt"
source2_file = "/tmp/4gtv_list.txt"
allowed_group2 = "4Gtv"

# 输出文件
output_file = "1.m3u"
# --- 配置结束 ---

def download_file(url, save_path):
    """使用 requests 下载文件，并处理 HTTP 错误"""
    try:
        print(f"Downloading {url}...")
        response = requests.get(url, timeout=10) # 设置超时
        response.raise_for_status() # 如果请求失败 (例如 404, 500), 则抛出异常
        with open(save_path, 'wb') as f:
            f.write(response.content)
        print(f"Successfully downloaded to {save_path}")
    except requests.exceptions.RequestException as e:
        print(f"ERROR downloading {url}: {e}")
        return False
    return True

def parse_m3u_robust(file_path, allowed_group):
    """更健壮地解析 M3U 文件，返回指定分组的频道列表"""
    entries = []
    group_title_regex = re.compile(r'group-title\s*=\s*["\']([^"\']+)["\']')
    
    try:
        # 尝试多种编码
        encodings = ['utf-8', 'gbk', 'gb18030', 'latin-1']
        content = None
        for encoding in encodings:
            try:
                with open(file_path, "r", encoding=encoding) as f:
                    content = f.readlines()
                break # 成功解码则跳出循环
            except UnicodeDecodeError:
                continue
        
        if content is None:
            print(f"Error: Could not decode {file_path} with any of the tried encodings.")
            return entries

        extinf_line = ""
        for line in content:
            line_stripped = line.strip()
            if line.startswith("#EXTINF:"): # 使用原始 line 检查，保留换行符等
                match = group_title_regex.search(line)
                if match and match.group(1) == allowed_group:
                    extinf_line = line # 保留原始格式
            elif extinf_line and line_stripped and not line_stripped.startswith("#"):
                entries.append(f"{extinf_line}{line}") # 直接追加原始 URL 行
                extinf_line = ""
            else:
                if not line.startswith("#EXTINF:"):
                    extinf_line = ""
    except FileNotFoundError:
        print(f"Warning: Source file not found at {file_path}")
    except Exception as e:
        print(f"Error parsing {file_path}: {e}")
    return entries

# 下载文件
download_success = True
if not download_file(source1_url, source1_file):
    download_success = False
if not download_file(source2_url, source2_file):
    download_success = False

if not download_success:
    print("Some files failed to download. Exiting processing.")
    # 根据需要决定是否退出脚本

# 读取旧文件中已存在的URL，用于去重
existing_urls = set()
output_path = Path(output_file)
file_header = "#EXTM3U\n"

if output_path.exists():
    try:
        with open(output_file, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip() and not line.startswith("#"):
                    existing_urls.add(line.strip())
    except Exception as e:
        print(f"Error reading existing {output_file}: {e}")
else:
    print(f"'{output_file}' not found, a new one will be created.")

# --- 处理第一个源 ---
print(f"--- Processing {source1_file} for group '{allowed_group1}' ---")
new_entries_source1 = parse_m3u_robust(source1_file, allowed_group1)
print(f"Found {len(new_entries_source1)} entries in '{allowed_group1}'.")

# --- 处理第二个源 ---
print(f"--- Processing {source2_file} for group '{allowed_group2}' ---")
new_entries_source2 = parse_m3u_robust(source2_file, allowed_group2)
print(f"Found {len(new_entries_source2)} entries in '{allowed_group2}'.")

# 合并并去重
all_new_entries = new_entries_source1 + new_entries_source2
entries_to_write = []
for entry in all_new_entries:
    # 从原始条目中提取 URL 行并去重
    url = entry.splitlines()[-1].strip()
    if url not in existing_urls:
        entries_to_write.append(entry)
        existing_urls.add(url)

# --- 写入新内容 ---
if entries_to_write:
    # 使用 'a+' 模式，以便在文件不存在时创建，并可以读取检查头部
    with open(output_file, "a+", encoding="utf-8") as f_out:
        # 移到文件开头检查是否有头部
        f_out.seek(0)
        first_line = f_out.readline()
        if not first_line.startswith(file_header.strip()):
            # 如果没有头部，则写入头部
            f_out.write(file_header)
        
        # 移到文件末尾准备追加
        f_out.seek(0, 2)
        for entry in entries_to_write:
            f_out.write(entry)
    print(f"\nSUCCESS: Appended {len(entries_to_write)} new unique entries to '{output_file}'.")
else:
    print("\nINFO: No new unique entries found to append.")
PY

      - name: Commit and push
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add 1.m3u
          if ! git diff --staged --quiet; then
            git commit -m "Auto update playlist (GPT-台湾 & 4Gtv) at $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
            git push
          else
            echo "No changes to commit."
          fi